# 自动化测试分析报告

## 命令概述

本文档分析了以下自动化测试命令：

```bash
python main.py auto_test --model_path Qwen/Qwen2.5-3B-Instruct --quant_types fp16 --attention_types standard,sparse,linear,reformer,linformer,longformer,realformer --monitor --save_results
```

该命令使用Qwen2.5-3B-Instruct模型，在fp16量化精度下，测试了7种不同的注意力机制，并监控硬件使用情况和保存测试结果。

## 测试组合概述

该命令会自动测试以下组合：

- **模型**: Qwen/Qwen2.5-3B-Instruct
- **量化类型**: fp16
- **注意力机制类型**: 7种不同类型
  - standard (标准注意力)
  - sparse (稀疏注意力)
  - linear (线性注意力)
  - reformer (Reformer注意力)
  - linformer (Linformer注意力)
  - longformer (Longformer注意力)
  - realformer (Realformer注意力)
- **批处理大小**: 1 (默认值)
- **输入长度**: 512, 1024, 2048 (默认值)
- **输出长度**: 128 (默认值)

总共测试组合数量 = 1(量化类型) × 7(注意力类型) × 1(批处理大小) × 3(输入长度) × 1(输出长度) = **21个测试组合**

## 测试配置详情

### 1. 模型配置

- **模型路径**: Qwen/Qwen2.5-3B-Instruct
- **模型类型**: 通义千问2.5 3B指令微调版本
- **量化方法**: fp16 (半精度浮点数)

### 2. 注意力机制配置

#### 2.1 标准注意力 (Standard Attention)

- **类型**: standard
- **描述**: 原始的自注意力机制，使用点积计算注意力权重
- **特点**: 计算复杂度为O(n²)，其中n为序列长度
- **参数**: 无特殊参数

#### 2.2 稀疏注意力 (Sparse Attention)

- **类型**: sparse
- **描述**: 通过稀疏化注意力矩阵减少计算量
- **特点**: 只计算部分token之间的注意力权重，降低计算复杂度
- **参数**:
  - **sparsity**: 0.8 (默认值，表示80%的注意力权重被置为0)

#### 2.3 线性注意力 (Linear Attention)

- **类型**: linear
- **描述**: 使用核函数将注意力计算复杂度从O(n²)降低到O(n)
- **特点**: 通过特征映射重写注意力计算，显著降低计算和内存需求
- **参数**:
  - **kernel_function**: "elu" (默认值，使用ELU激活函数作为核函数)

#### 2.4 Reformer注意力

- **类型**: reformer
- **描述**: 使用局部敏感哈希(LSH)降低注意力计算复杂度
- **特点**: 将相似的向量分组，只在组内计算注意力
- **参数**:
  - **num_hashes**: 4 (默认值，哈希函数数量)

#### 2.5 Linformer注意力

- **类型**: linformer
- **描述**: 通过低秩矩阵近似实现线性复杂度的注意力机制
- **特点**: 使用投影矩阵将序列长度维度降低
- **参数**:
  - **k_ratio**: 0.25 (默认值，投影维度与原始序列长度的比例)
  - **max_seq_length**: 根据输入长度设置 (512/1024/2048)

#### 2.6 Longformer注意力

- **类型**: longformer
- **描述**: 结合局部窗口注意力和全局注意力处理长序列
- **特点**: 对每个token只计算窗口内和全局token的注意力
- **参数**:
  - **window_size**: 128 (默认值，局部窗口大小)
  - **global_tokens_ratio**: 0.1 (默认值，全局token的比例)

#### 2.7 Realformer注意力

- **类型**: realformer
- **描述**: 使用残差注意力连接增强模型性能
- **特点**: 在层间传递注意力权重，增强模型表达能力
- **参数**: 无特殊参数

### 3. 测试参数配置

- **批处理大小**: 1 (默认值)
- **输入长度**: 测试了三种不同的输入长度
  - 512 tokens
  - 1024 tokens
  - 2048 tokens
- **输出长度**: 128 tokens (默认值)
- **预热运行次数**: 2 (默认值)
- **测试运行次数**: 3 (默认值)

### 4. 测试用例

测试使用了以下8种测试用例，每个测试组合最多使用前3个测试用例：

1. **基础测试**: 简单的自我介绍提示
2. **复杂推理测试**: 逻辑推理问题
3. **多轮对话测试**: 关于量子计算的专业对话

其他可用但未使用的测试用例：
4. 长文本生成测试
5. 多语言混合测试
6. 代码生成测试
7. 数学问题测试
8. 创意写作测试

### 5. 监控和结果保存

- **硬件监控**: 启用 (--monitor)
  - 监控CPU使用率
  - 监控GPU使用率
  - 监控内存使用情况
  - 监控GPU显存使用情况
  - 监控温度

- **结果保存**: 启用 (--save_results)
  - 保存每个测试组合的详细结果
  - 保存硬件监控数据
  - 默认保存在data/results目录下

## 测试指标

每个测试组合会收集以下性能指标：

1. **延迟 (Latency)**: 生成响应所需的时间 (毫秒)
2. **生成速度 (Tokens per Second)**: 每秒生成的token数量
3. **内存使用 (Memory Usage)**: 模型运行时的内存占用 (MB)
4. **困惑度 (Perplexity)**: 模型对输入文本的预测准确度指标

## 结果分析

测试完成后，可以使用以下命令分析结果：

```bash
python main.py analyze --results_dir data/results --metrics latency,tokens_per_second,memory_usage,perplexity
```

分析将比较不同注意力机制在各种输入长度下的性能表现，帮助确定哪种注意力机制在特定场景下最为高效。 